from pyspark.sql import SparkSession, functions as F
from pyspark.sql.window import Window
from pyspark.ml.feature import StringIndexer
from pyspark.ml.recommendation import ALS

# =====================================================
# 0️⃣ Spark Session
# =====================================================
spark = SparkSession.builder.getOrCreate()

# =====================================================
# 1️⃣ ALS Training Prep
# =====================================================
df_als_prep = df_final.select("user_id", "skuCode", "total").dropna(subset=["user_id", "skuCode"])

# Index user_id and skuCode
user_indexer = StringIndexer(inputCol="user_id", outputCol="userIdx", handleInvalid="skip")
item_indexer = StringIndexer(inputCol="skuCode", outputCol="itemIdx", handleInvalid="skip")

ui_model = user_indexer.fit(df_als_prep)
ii_model = item_indexer.fit(df_als_prep)

df_als_indexed = ui_model.transform(df_als_prep)
df_als_indexed = ii_model.transform(df_als_indexed)

df_als_indexed = df_als_indexed.withColumn("userIdx", F.col("userIdx").cast("int")) \
                               .withColumn("itemIdx", F.col("itemIdx").cast("int"))

# =====================================================
# 2️⃣ Train ALS model
# =====================================================
als = ALS(
    userCol="userIdx",
    itemCol="itemIdx",
    ratingCol="total",
    implicitPrefs=True,
    rank=70,
    regParam=0.05,
    alpha=40,
    coldStartStrategy="drop",
    nonnegative=True,
    maxIter=15
)

als_model = als.fit(df_als_indexed)

# =====================================================
# 3️⃣ Mapping for decoding
# =====================================================
item_idx_map = df_als_indexed.select("itemIdx", "skuCode").dropDuplicates(["itemIdx"])
user_idx_map = df_als_indexed.select("userIdx", "user_id").dropDuplicates(["userIdx"])

# =====================================================
# 4️⃣ ALS Recommendations
# =====================================================
als_user_recs = als_model.recommendForAllUsers(200)  # Top 200 recommendations

als_exp = (
    als_user_recs
    .select("userIdx", F.explode("recommendations").alias("rec"))
    .select(
        "userIdx",
        F.col("rec.itemIdx").alias("itemIdx"),
        F.col("rec.rating").alias("als_score")
    )
    .join(user_idx_map, on="userIdx", how="left")
    .join(item_idx_map, on="itemIdx", how="left")
    .select("user_id", "skuCode", "als_score")
)

# =====================================================
# 5️⃣ Enrich with metadata
# =====================================================
als_enriched = (
    als_exp.join(df_category, on="skuCode", how="left")
    .select("user_id", "skuCode", "als_score", "subCategoryName", "brandName")
    .withColumn("batch_date", F.current_date())
)

# =====================================================
# 6️⃣ Brand-wise ALS top 10 per user
# =====================================================
als_brand_recos = (
    als_enriched
    .withColumn(
        "rank",
        F.row_number().over(
            Window.partitionBy("user_id", "brandName").orderBy(F.desc("als_score"))
        )
    )
    .filter(F.col("rank") <= 10)
)

als_brand_recos.write.mode("overwrite").saveAsTable("cdp.product_reccomendation.als_brand_recos_table")

# =====================================================
# 7️⃣ Brand popularity
# =====================================================
brand_popularity = (
    df_final.groupBy("brandName", "skuCode", "subCategoryName")
    .agg(F.sum("total").alias("sales_count"))
    .withColumn(
        "rank",
        F.row_number().over(Window.partitionBy("brandName").orderBy(F.desc("sales_count")))
    )
)

brand_popularity.write.mode("overwrite").saveAsTable("cdp.product_reccomendation.brand_popularity_table")

# =====================================================
# 8️⃣ Subcategory popularity
# =====================================================
subcategory_popularity = (
    df_final.groupBy("subCategoryName", "skuCode", "brandName")
    .agg(F.sum("total").alias("sales_count"))
    .withColumn(
        "rank",
        F.row_number().over(Window.partitionBy("subCategoryName").orderBy(F.desc("sales_count")))
    )
)

subcategory_popularity.write.mode("overwrite").saveAsTable("cdp.product_reccomendation.subcategory_popularity_table")

# =====================================================
# 9️⃣ Overall popularity
# =====================================================
overall_popularity = (
    df_final.groupBy("skuCode", "brandName", "subCategoryName")
    .agg(F.sum("total").alias("sales_count"))
    .orderBy(F.desc("sales_count"))
)

overall_popularity.write.mode("overwrite").saveAsTable("cdp.product_reccomendation.overall_popularity_table")








from pyspark.sql import SparkSession, functions as F

spark = SparkSession.builder.getOrCreate()

# =====================================================
# Load all prepared tables
# =====================================================
als_brand_recos_table = spark.table("cdp.product_reccomendation.als_brand_recos_table")
brand_popularity_table = spark.table("cdp.product_reccomendation.brand_popularity_table")
subcategory_popularity_table = spark.table("cdp.product_reccomendation.subcategory_popularity_table")
overall_popularity_table = spark.table("cdp.product_reccomendation.overall_popularity_table")
df_category = spark.table("cdp.product_reccomendation.category_filtered")

# =====================================================
# Recommendation Function
# =====================================================
def get_user_recommendations(user_id, current_sku):
    # Step 1️⃣ — Check if SKU present in df_category
    sku_data = (
        df_category.filter(F.col("skuCode") == current_sku)
        .select("brandName", "subCategoryName")
        .first()
    )

    if not sku_data:
        return f"SKU {current_sku} not found in df_category."

    brandName = sku_data["brandName"]
    subCategoryName = sku_data["subCategoryName"]

    # Step 2️⃣ — Check if user exists in ALS table
    user_exists = (
        als_brand_recos_table.filter(F.col("user_id") == user_id).limit(1).count() > 0
    )

    # Helper: keep recos unique and limited to 5
    def merge_recos(base_df, add_df, n_needed):
        return (
            base_df.union(add_df)
            .dropDuplicates(["skuCode"])
            .orderBy(F.rand())  # randomize merged results as well
            .limit(5)
        )

    # =====================================================
    # Step 3️⃣ — ALS Flow
    # =====================================================
    if user_exists:
        # a) Brand-based ALS recommendations (RANDOM)
        als_brand_recos = (
            als_brand_recos_table
            .filter(
                (F.col("user_id") == user_id) &
                (F.col("brandName") == brandName)
            )
            .orderBy(F.rand())  # randomize instead of sorting by score
            .select("skuCode", "brandName", "subCategoryName")
        )

        final_recos = als_brand_recos.limit(5)
        count_als = final_recos.count()
        remaining = 5 - count_als

        # b) Backfill from ALS subcategory (RANDOM)
        if remaining > 0:
            als_subcat_recos = (
                als_brand_recos_table
                .filter(
                    (F.col("user_id") == user_id) &
                    (F.col("subCategoryName") == subCategoryName)
                )
                .orderBy(F.rand())
                .select("skuCode", "brandName", "subCategoryName")
                .limit(remaining * 2)
            )
            final_recos = merge_recos(final_recos, als_subcat_recos, remaining)
            remaining = 5 - final_recos.count()

        # c) Backfill from Brand Popularity (RANDOM)
        if remaining > 0:
            brand_pop = (
                brand_popularity_table
                .filter(F.col("brandName") == brandName)
                .orderBy(F.rand())
                .select("skuCode", "brandName", "subCategoryName")
                .limit(remaining * 2)
            )
            final_recos = merge_recos(final_recos, brand_pop, remaining)
            remaining = 5 - final_recos.count()

        # d) Backfill from Overall Popularity (RANDOM)
        if remaining > 0:
            overall_pop = (
                overall_popularity_table
                .orderBy(F.rand())
                .select("skuCode", "brandName", "subCategoryName")
            )
            final_recos = merge_recos(final_recos, overall_pop, remaining)

        # Add user_id and source info
        final_recos = (
            final_recos
            .withColumn("user_id", F.lit(user_id))
            .withColumn("source", F.lit("ALS Hierarchy (Random): Brand → Subcat → Pop"))
        )

        return final_recos.limit(5)

    # =====================================================
    # Step 4️⃣ — Cold Start User (no ALS history)
    # =====================================================
    else:
        # a) Brand Popularity (RANDOM)
        brand_recos = (
            brand_popularity_table
            .filter(F.col("brandName") == brandName)
            .orderBy(F.rand())
            .select("skuCode", "brandName", "subCategoryName")
        )

        final_recos = brand_recos.limit(5)
        remaining = 5 - final_recos.count()

        # b) Subcategory Popularity (RANDOM)
        if remaining > 0:
            sub_pop = (
                subcategory_popularity_table
                .filter(F.col("subCategoryName") == subCategoryName)
                .orderBy(F.rand())
                .select("skuCode", "brandName", "subCategoryName")
                .limit(remaining * 2)
            )
            final_recos = merge_recos(final_recos, sub_pop, remaining)
            remaining = 5 - final_recos.count()

        # c) Overall Popularity (RANDOM)
        if remaining > 0:
            overall_pop = (
                overall_popularity_table
                .orderBy(F.rand())
                .select("skuCode", "brandName", "subCategoryName")
            )
            final_recos = merge_recos(final_recos, overall_pop, remaining)

        # Add user_id and source info
        final_recos = (
            final_recos
            .withColumn("user_id", F.lit(user_id))
            .withColumn("source", F.lit("Cold Start (Random): Brand → Subcat → Pop"))
        )

        return final_recos.limit(5)








2nd approach

from pyspark.sql import functions as F

def get_user_recommendations(user_id, current_sku):
    # Step 1️⃣ — Check if SKU present in df_category
    sku_data = (
        df_category.filter(F.col("skuCode") == current_sku)
        .select("brandName", "subCategoryName")
        .first()
    )
    if not sku_data:
        return f"SKU {current_sku} not found in df_category."

    brandName = sku_data["brandName"]
    subCategoryName = sku_data["subCategoryName"]

    # Step 2️⃣ — Check if user exists in ALS table
    user_exists = (
        als_brand_recos_table.filter(F.col("user_id") == user_id).limit(1).count() > 0
    )

    # Helper to randomly pick up to n rows efficiently (no full shuffle)
    def random_limit(df, n):
        count = df.count()
        if count == 0:
            return spark.createDataFrame([], df.schema)
        fraction = min(1.0, (n * 2) / count)
        return df.sample(withReplacement=False, fraction=fraction).limit(n)

    # Helper to merge recommendations (keep unique SKUs)
    def merge_recos(base_df, add_df):
        return (
            base_df.union(add_df)
            .dropDuplicates(["skuCode"])
            .limit(5)
        )

    # =====================================================
    # Step 3️⃣ — ALS Flow
    # =====================================================
    if user_exists:
        # a) ALS brand recommendations (randomly pick)
        als_brand_recos = (
            als_brand_recos_table
            .filter((F.col("user_id") == user_id) & (F.col("brandName") == brandName))
            .select("skuCode", "brandName", "subCategoryName")
        )

        final_recos = random_limit(als_brand_recos, 5)
        remaining = 5 - final_recos.count()

        # b) Backfill from ALS subcategory
        if remaining > 0:
            als_subcat_recos = (
                als_brand_recos_table
                .filter((F.col("user_id") == user_id) & (F.col("subCategoryName") == subCategoryName))
                .select("skuCode", "brandName", "subCategoryName")
            )
            final_recos = merge_recos(final_recos, random_limit(als_subcat_recos, remaining))
            remaining = 5 - final_recos.count()

        # c) Brand popularity
        if remaining > 0:
            brand_pop = (
                brand_popularity_table
                .filter(F.col("brandName") == brandName)
                .select("skuCode", "brandName", "subCategoryName")
            )
            final_recos = merge_recos(final_recos, random_limit(brand_pop, remaining))
            remaining = 5 - final_recos.count()

        # d) Overall popularity
        if remaining > 0:
            overall_pop = (
                overall_popularity_table
                .select("skuCode", "brandName", "subCategoryName")
            )
            final_recos = merge_recos(final_recos, random_limit(overall_pop, remaining))

        final_recos = (
            final_recos
            .withColumn("user_id", F.lit(user_id))
            .withColumn("source", F.lit("ALS Hierarchy (Random Sample): Brand → Subcat → Pop"))
        )

        return final_recos.limit(5)

    # =====================================================
    # Step 4️⃣ — Cold Start Flow
    # =====================================================
    else:
        # a) Brand popularity (random)
        brand_recos = (
            brand_popularity_table
            .filter(F.col("brandName") == brandName)
            .select("skuCode", "brandName", "subCategoryName")
        )
        final_recos = random_limit(brand_recos, 5)
        remaining = 5 - final_recos.count()

        # b) Subcategory popularity
        if remaining > 0:
            sub_pop = (
                subcategory_popularity_table
                .filter(F.col("subCategoryName") == subCategoryName)
                .select("skuCode", "brandName", "subCategoryName")
            )
            final_recos = merge_recos(final_recos, random_limit(sub_pop, remaining))
            remaining = 5 - final_recos.count()

        # c) Overall popularity
        if remaining > 0:
            overall_pop = overall_popularity_table.select("skuCode", "brandName", "subCategoryName")
            final_recos = merge_recos(final_recos, random_limit(overall_pop, remaining))

        final_recos = (
            final_recos
            .withColumn("user_id", F.lit(user_id))
            .withColumn("source", F.lit("Cold Start (Random Sample): Brand → Subcat → Pop"))
        )

        return final_recos.limit(5)





# Example inputs
user_id = "U12345"
current_sku = "SKU98765"

# Call the function
recommendations_df = get_user_recommendations(user_id, current_sku)

# Show results in Spark DataFrame form
recommendations_df.show(truncate=False)
